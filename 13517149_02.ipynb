{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "13517149-02.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPxRv2nmfs2DHhy/a9puHri",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fajarmuslim/spam-classification/blob/master/13517149_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTHxM7Hlc_t9"
      },
      "source": [
        "# Preparing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCuOfTbZETwm"
      },
      "source": [
        "I save experiment data (data on task spesification google classroom) into Github"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQRsL37rciCt",
        "outputId": "d047a127-c197-421f-f178-91423af0432a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "#get data from source\n",
        "!git clone https://github.com/fajarmuslim/dataset.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'dataset'...\n",
            "remote: Enumerating objects: 240, done.\u001b[K\n",
            "remote: Counting objects: 100% (240/240), done.\u001b[K\n",
            "remote: Compressing objects: 100% (238/238), done.\u001b[K\n",
            "remote: Total 240 (delta 1), reused 236 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (240/240), 4.90 MiB | 3.98 MiB/s, done.\n",
            "Resolving deltas: 100% (1/1), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3NX4GS1EjtO",
        "outputId": "295b2ddf-a6f2-48f8-ed65-8045db18d0fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "#data processing\n",
        "import pandas as pd\n",
        "\n",
        "#grid search cv to get best parameter\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "#ML model that used on this experiment\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "#metrics to evaluate model\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
        "\n",
        "import string\n",
        "from nltk.stem import SnowballStemmer\n",
        "\n",
        "#library for natural language processing\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "#tf idf\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnccBVtSEuFj"
      },
      "source": [
        "#read dataset\n",
        "train_data = pd.read_csv(\"dataset/spam/training_data.csv\")\n",
        "test_data = pd.read_csv(\"dataset/spam/testing_data.csv\")\n",
        "val_data = pd.read_csv(\"dataset/spam/val_data.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpFzMVsC-zYb"
      },
      "source": [
        "# Exploratory Dana Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_xSCJIkAK_O"
      },
      "source": [
        "### See data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGrxs08PAQ5B",
        "outputId": "f191918b-9fd2-4734-87a7-3e311682d3a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Babe, I'm back ... Come back to me ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>S:)no competition for him.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ham</td>\n",
              "      <td>Yup having my lunch buffet now.. U eat already?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>Storming msg: Wen u lift d phne, u say HELLO D...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Mark works tomorrow. He gets out at 5. His wor...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  type                                               text\n",
              "0  ham             Babe, I'm back ... Come back to me ...\n",
              "1  ham                         S:)no competition for him.\n",
              "2  ham    Yup having my lunch buffet now.. U eat already?\n",
              "3  ham  Storming msg: Wen u lift d phne, u say HELLO D...\n",
              "4  ham  Mark works tomorrow. He gets out at 5. His wor..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FNpxjdCAeGE",
        "outputId": "c2cb8aaf-d577-42b1-fa3a-7a80f2b3ab47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "val_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>We can make a baby in yo tho</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Aight will do, thanks again for comin out</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ham</td>\n",
              "      <td>hope things went well at 'doctors' ;) reminds ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>Thanks for this hope you had a good day today</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>No i'm not. I can't give you everything you wa...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  type                                               text\n",
              "0  ham                       We can make a baby in yo tho\n",
              "1  ham          Aight will do, thanks again for comin out\n",
              "2  ham  hope things went well at 'doctors' ;) reminds ...\n",
              "3  ham      Thanks for this hope you had a good day today\n",
              "4  ham  No i'm not. I can't give you everything you wa..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDRYXTd1Ajnf",
        "outputId": "9f74790a-0e70-4b7f-b569-ef1063b19d2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "test_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Anything lor... U decide...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>So u pay first lar... Then when is da stock co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ham</td>\n",
              "      <td>I got a call from a landline number. . . I am ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>Cool. So how come you havent been wined and di...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Dunno lei u all decide lor. How abt leona? Oop...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  type                                               text\n",
              "0  ham                        Anything lor... U decide...\n",
              "1  ham  So u pay first lar... Then when is da stock co...\n",
              "2  ham  I got a call from a landline number. . . I am ...\n",
              "3  ham  Cool. So how come you havent been wined and di...\n",
              "4  ham  Dunno lei u all decide lor. How abt leona? Oop..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVlnheyX--vf"
      },
      "source": [
        "### Data size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zbVgNQF_E7_",
        "outputId": "704a04f9-a2e0-456a-bd5f-26ecfdf9677d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "print(\"ukuran training data\")\n",
        "print(train_data.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ukuran training data\n",
            "(4502, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3dxicim_L5u",
        "outputId": "437e8224-5e65-4186-dd3f-f27e666e543b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "print(\"ukuran val data\")\n",
        "print(val_data.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ukuran val data\n",
            "(501, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8jcLmis_P7i",
        "outputId": "4308eb7b-6514-4d49-a333-e1741e40eb23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "print(\"ukuran testing data\")\n",
        "print(test_data.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ukuran testing data\n",
            "(556, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVaSzx4s_hhL",
        "outputId": "49d5874f-2b86-4420-e073-20928a90ca74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len_total_data = len(train_data) + len(test_data) + len(val_data)\n",
        "print(\"data total ada \", len_total_data, \" baris\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data total ada  5559  baris\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jO7bOOkL_z-y",
        "outputId": "8c567e62-e8f3-404b-b464-f2d58404bdc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(\"presentase training data : \", (len(train_data) / len_total_data)*100, \"%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "presentase training data :  80.98578881093722 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9o7xQknAC5H",
        "outputId": "30fe8f72-6557-4903-8e96-476f1247560b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(\"presentase validation data : \", (len(val_data) / len_total_data)*100, \"%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "presentase validation data :  9.01241230437129 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyaJ_j6n__d8",
        "outputId": "99c43df6-3bb3-42ad-c0c7-922a4a69e4c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(\"presentase testing data : \", (len(test_data) / len_total_data)*100, \"%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "presentase testing data :  10.00179888469149 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F32jTPT7_Uef"
      },
      "source": [
        "Ukuran training sudah cukup besar jika dibandingkan dengan ukuran testing dan validation. Hal ini menunjukkan data sudah cukup bagus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7AeKWeR-15_"
      },
      "source": [
        "### See whether the data contain null value or not"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMZLdq2wFxT9",
        "outputId": "235e0b60-fd57-43fa-f368-7f1e5e091b32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"nilai null pada train data\")\n",
        "print(train_data.isnull().sum())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nilai null pada train data\n",
            "type    0\n",
            "text    0\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EI34AFOWF2Od",
        "outputId": "77037871-089e-42d4-b233-efe09eb142b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"nilai null pada val data\")\n",
        "print(val_data.isnull().sum())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nilai null pada val data\n",
            "type    0\n",
            "text    0\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCe6sOV8Fzr_",
        "outputId": "72dcdf3c-6c50-45f6-954e-f01669bb821d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"nilai null pada test data\")\n",
        "print(test_data.isnull().sum())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nilai null pada test data\n",
            "type    0\n",
            "text    0\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnNSPTvh-4zA"
      },
      "source": [
        "Pada data tidak terdapat nilai null sehingga bisa dilanjutkan ke proses berikutnya"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37-m7K5H-QMX"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UaBJJilA18m",
        "outputId": "80e504cb-63ce-40ec-c374-a322c8d3c004",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import sys \n",
        "!{sys.executable} -m pip install pyspellchecker "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyspellchecker in /usr/local/lib/python3.6/dist-packages (0.5.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WF5mUBqjK6OO"
      },
      "source": [
        "#### Remove punctuation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZaS65zRKeyJ"
      },
      "source": [
        "Text data contain punctuation that doesn't adding value on this spam classification\n",
        "\n",
        "Punctuation can be act as noise\n",
        "\n",
        "So, i decide to remove puctuation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-2xDIaV2eM6"
      },
      "source": [
        "def remove_puctuation(text):\n",
        "  return text.translate(str.maketrans('','', string.punctuation))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFhNrkC8K-Vi"
      },
      "source": [
        "### Lowering case"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vae4gERLDOp"
      },
      "source": [
        "Text contain upper case and lowercase char\n",
        "\n",
        "\n",
        "So, i decide to lowering case for all word in the data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9QGPMEL20if"
      },
      "source": [
        "def lowering_case(text):\n",
        "  return text.lower()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMZhRiCOLhMv"
      },
      "source": [
        "### Remove Stopword"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwpu1e1oLkg6"
      },
      "source": [
        "Stopword doen't add value to spam or not, because stopword show on both of text spam or text not spam frequently and have netral meaning\n",
        "\n",
        "So, i decide to remove stopword"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoxkmvHe24CZ"
      },
      "source": [
        "def remove_stopwords(text):\n",
        "  return [word for word in text.split() if word.lower() not in stopwords.words('english')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "US0SxGAXL53B"
      },
      "source": [
        "### Doing stemming"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhkjeftrL86R"
      },
      "source": [
        "Reducing inflected (or sometimes derived) words to their word stem\n",
        "\n",
        "By doing stemming, many word that have close semantics will have close character\n",
        "\n",
        "So, i decide to use stemming to preprocess text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53a06Ok53G1Q"
      },
      "source": [
        "def doing_stemming(array_of_words):\n",
        "  words = \"\"\n",
        "  for i in array_of_words:\n",
        "    stemmer = SnowballStemmer(\"english\")\n",
        "    words += (stemmer.stem(i))+\" \"\n",
        "  return words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukHBUzDyMom_"
      },
      "source": [
        "### Apply all preprocess on the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrskORde-SIx"
      },
      "source": [
        "text_train = train_data['text'].copy()\n",
        "text_train = text_train.apply(remove_puctuation)\n",
        "text_train = text_train.apply(lowering_case)\n",
        "text_train = text_train.apply(remove_stopwords)\n",
        "text_train = text_train.apply(doing_stemming)\n",
        "\n",
        "text_val = val_data['text'].copy()\n",
        "text_val = text_val.apply(remove_puctuation)\n",
        "text_val = text_val.apply(lowering_case)\n",
        "text_val = text_val.apply(remove_stopwords)\n",
        "text_val = text_val.apply(doing_stemming)\n",
        "\n",
        "text_test = test_data['text'].copy()\n",
        "text_test = text_test.apply(remove_puctuation)\n",
        "text_test = text_test.apply(lowering_case)\n",
        "text_test = text_test.apply(remove_stopwords)\n",
        "text_test = text_test.apply(doing_stemming)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ME9-Hd-xDR77"
      },
      "source": [
        "# Feature Extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkGkABUYMws6"
      },
      "source": [
        "##TF-IDF to extract feature"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ar2siDLrM0bK"
      },
      "source": [
        "TF IDF shows how important a word to a document in a coppus\n",
        "\n",
        "In this experiment i use TF IDF to extract feature from text. \n",
        "\n",
        "The reason is TF IDF can intent the important of word"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivQvwv7qHbSs"
      },
      "source": [
        "def extract_features(text_train, text_val, text_test):\n",
        "\n",
        "  vectorizer = TfidfVectorizer(\"english\")\n",
        "  \n",
        "  #fit and tranform text into vector\n",
        "  features_train = vectorizer.fit_transform(text_train)\n",
        "\n",
        "  #transform text using vectorizer on text_train\n",
        "  features_val = vectorizer.transform(text_val)\n",
        "\n",
        "  #transform text using vectorizer on text_train\n",
        "  features_test = vectorizer.transform(text_test)\n",
        "  \n",
        "  return features_train, features_val, features_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eV1nI5j4JjQW"
      },
      "source": [
        "#extract features\n",
        "features_train, features_val, features_test = extract_features(text_train, text_val, text_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiBKdSlZIjj6"
      },
      "source": [
        "#convert string label into int label\n",
        "def is_spam(spam_or_ham):\n",
        "  if(spam_or_ham == \"spam\"):\n",
        "    return 1\n",
        "  elif(spam_or_ham == \"ham\"):\n",
        "    return 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XQpEIQJIcKj"
      },
      "source": [
        "#extract label\n",
        "labels_train = train_data['type'].apply(is_spam)\n",
        "labels_test = test_data['type'].apply(is_spam)\n",
        "labels_val = val_data['type'].apply(is_spam)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r08ETxxMQeKj"
      },
      "source": [
        "# Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQmBJ1yURq2k"
      },
      "source": [
        "### Training and Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLEolicqQfrS"
      },
      "source": [
        "In this stage i use some of machine learning model\n",
        "\n",
        "\n",
        "1.   MultinomialNB (Probabilistic based)\n",
        "2.   SVC (Optimum separating line/plane)\n",
        "3.   RandomForestClassifier (Tree based)\n",
        "\n",
        "The reason for the choice is because I will try to use different kinds of machine learning with different learning types. So, i will have good benchmarking\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0rp2iBiUr0-"
      },
      "source": [
        "For every machine learning model that used here, the step is : \n",
        "\n",
        "1.   Doing parameter tuning to get best parameter\n",
        "2.   Validate model using validation data\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_0DT2ctFSkb"
      },
      "source": [
        "## Hyperparameter Tuning MultinomialNB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1xsMHs2FXUP"
      },
      "source": [
        "def hyperparameter_tuning_multinomialNB(features_train, labels_train):\n",
        "  parameter_candidates = [\n",
        "    {'alpha': [0.01, 0.05, 0.1, 0.3 ,0.5, 1.0, 3.0]},\n",
        "  ]\n",
        "\n",
        "  # Create a GridSearchCV object with the classifier model and parameter candidates\n",
        "  clf = GridSearchCV(estimator=MultinomialNB(), param_grid=parameter_candidates, n_jobs=-1)\n",
        "\n",
        "  # Train the classifier on train feature and labels train\n",
        "  clf.fit(features_train, labels_train) \n",
        "\n",
        "  # Print accuracy score\n",
        "  print('Best score for data1:', clf.best_score_)\n",
        "\n",
        "  # Print best parameters for the model found using grid search\n",
        "  print('Best alpha:',clf.best_estimator_.alpha) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEUYnrDtF_ao",
        "outputId": "7ba3a787-7de1-4580-e8b6-a34960e2808b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "hyperparameter_tuning_multinomialNB(features_train, labels_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best score for data1: 0.9782311012455296\n",
            "Best alpha: 0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aElAI34ML04a",
        "outputId": "aa56aa79-cb4e-49e9-cca3-1e4a51740ea3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Validate the model using best parameters found by the grid search\n",
        "MultinomialNB(alpha=0.1).fit(features_train, labels_train).score(features_val, labels_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9920159680638723"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPsEvcP2AE-h"
      },
      "source": [
        "## Hyperparameter Tuning SVC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyN6LVizBY8X"
      },
      "source": [
        "def hyperparameter_tuning_svc(features_train, labels_train):\n",
        "  parameter_candidates = [\n",
        "    {'C': [1, 10, 100, 1000], 'gamma': [0.1, 0.001, 0.0001], 'kernel': ['rbf', 'sigmoid']},\n",
        "  ]\n",
        "\n",
        "  # Create a GridSearchCV object with the classifier model and parameter candidates\n",
        "  grid_search_cv = GridSearchCV(estimator=SVC(), param_grid=parameter_candidates, n_jobs=-1)\n",
        "\n",
        "  # Train the classifier on train feature and labels train\n",
        "  grid_search_cv.fit(features_train, labels_train) \n",
        "\n",
        "  # Print accuracy score\n",
        "  print('Best score for data1:', grid_search_cv.best_score_)\n",
        "\n",
        "  # Print best parameters for the model found using grid search\n",
        "  print('Best C:',grid_search_cv.best_estimator_.C) \n",
        "  print('Best Kernel:',grid_search_cv.best_estimator_.kernel)\n",
        "  print('Best Gamma:',grid_search_cv.best_estimator_.gamma)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywI8O9XI8Gqn",
        "outputId": "cce5d1f1-4249-49ca-dcaa-91cfbca6f354",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "hyperparameter_tuning_svc(features_train, labels_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best score for data1: 0.9788972746331236\n",
            "Best C: 1000\n",
            "Best Kernel: rbf\n",
            "Best Gamma: 0.001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qFPOyqf_Hah",
        "outputId": "89382ef5-8953-4bf6-b8d5-6b8da9e1bffe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Validate the model using best parameters found by the grid search\n",
        "SVC(C=1000, kernel='rbf', gamma=0.001).fit(features_train, labels_train).score(features_val, labels_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9960079840319361"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DY6fIUGbPXqF"
      },
      "source": [
        "## Hyperparameter Tuning RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqaTCai-LzTb"
      },
      "source": [
        "def hyperparameter_tuning_RandomForestClassifier(features_train, labels_train):\n",
        "  parameter_candidates = [\n",
        "    {'n_estimators':[50, 100, 300],'criterion':['gini', 'entropy']},\n",
        "  ]\n",
        "\n",
        "  # Create a GridSearchCV object with the classifier model and parameter candidates\n",
        "  clf = GridSearchCV(estimator=RandomForestClassifier(), param_grid=parameter_candidates, n_jobs=-1)\n",
        "\n",
        "  # Train the classifier on train feature and labels train\n",
        "  clf.fit(features_train, labels_train) \n",
        "\n",
        "  # Print accuracy score\n",
        "  print('Best score for data1:', clf.best_score_)\n",
        "\n",
        "  # Print best parameters for the model found using grid search\n",
        "  print('Best n_estimators:',clf.best_estimator_.n_estimators) \n",
        "  print('Best criterion:',clf.best_estimator_.criterion) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUz165h0NH-H",
        "outputId": "b7749ea7-4247-4630-97cd-5c31593f39e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# Validate the model using best parameters found by the grid search\n",
        "hyperparameter_tuning_RandomForestClassifier(features_train, labels_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best score for data1: 0.9713434455543222\n",
            "Best n_estimators: 50\n",
            "Best criterion: gini\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RDpXgVaNQ7d",
        "outputId": "69a17192-721c-453b-a6a5-bc19d3073c3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "RandomForestClassifier(n_estimators=300, criterion='gini').fit(features_train, labels_train).score(features_val, labels_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9780439121756487"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XV8XIxh2NUKr"
      },
      "source": [
        "# Testing Stage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Od3_77oVP71U"
      },
      "source": [
        "#this function used to test using testing_data.csv\n",
        "def testing(features_train, features_test, labels_train, labels_test):\n",
        "    \n",
        "    #list of model used on validation phase\n",
        "    models = [\n",
        "      ['MultinomialNB: ', MultinomialNB(alpha=0.1)],\n",
        "      ['SVC: ', SVC(C=1000, kernel='rbf', gamma=0.001)],\n",
        "      ['RandomForestClassifier', RandomForestClassifier(n_estimators=300, criterion='gini')]\n",
        "    ]\n",
        "\n",
        "  \n",
        "    model_data = []\n",
        "    for name,current_model in models :\n",
        "      #current model will save metric score for current model\n",
        "      current_model_data = {}\n",
        "      current_model_data[\"model name\"] = name\n",
        "\n",
        "      #traning phase\n",
        "      current_model.fit(features_train, labels_train)\n",
        "      \n",
        "      #testing phase\n",
        "      #predict on testing data to know how better model predict on unseen data and identify is it overfitting or not\n",
        "      prediction_test = current_model.predict(features_test)\n",
        "      \n",
        "      #calculate accuracy score\n",
        "      current_model_data[\"test_accuracy\"] = accuracy_score(labels_test,prediction_test)\n",
        "\n",
        "      #calculate f1 score\n",
        "      current_model_data[\"test_f1\"] = f1_score(labels_test,prediction_test)\n",
        "      \n",
        "      #calculate precision score\n",
        "      current_model_data[\"test_precision\"] = precision_score(labels_test,prediction_test)\n",
        "      \n",
        "      #calculate recall score\n",
        "      current_model_data[\"test_recall\"] = recall_score(labels_test,prediction_test)\n",
        "\n",
        "      model_data.append(current_model_data)\n",
        "\n",
        "    #convert model_data into dataframe\n",
        "    return pd.DataFrame(model_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2nbHSY1SbE3",
        "outputId": "b0cd3ab5-4e0e-4449-f030-a223ce2e32cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "source": [
        "testing(features_train, features_test, labels_train, labels_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model name</th>\n",
              "      <th>test_accuracy</th>\n",
              "      <th>test_f1</th>\n",
              "      <th>test_precision</th>\n",
              "      <th>test_recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>MultinomialNB:</td>\n",
              "      <td>0.985612</td>\n",
              "      <td>0.941176</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.888889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SVC:</td>\n",
              "      <td>0.983813</td>\n",
              "      <td>0.935252</td>\n",
              "      <td>0.970149</td>\n",
              "      <td>0.902778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RandomForestClassifier</td>\n",
              "      <td>0.978417</td>\n",
              "      <td>0.910448</td>\n",
              "      <td>0.983871</td>\n",
              "      <td>0.847222</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               model name  test_accuracy   test_f1  test_precision  test_recall\n",
              "0         MultinomialNB:        0.985612  0.941176        1.000000     0.888889\n",
              "1                   SVC:        0.983813  0.935252        0.970149     0.902778\n",
              "2  RandomForestClassifier       0.978417  0.910448        0.983871     0.847222"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aX2YlcYPRulm"
      },
      "source": [
        "This result shows that MultinomialNB achieve best result on accuracy, f1, and recall. Also still competitive on precision. \n",
        "\n",
        "So, i decide to choose MultinomialNB as a classifier model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEjzi6ypXDxK"
      },
      "source": [
        "# Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_bg0PxuXE_m"
      },
      "source": [
        "In this experiment, we conclude that for spam/not spam classification tasks with a given dataset (used in this experiment). **MultinomialNB** achieves the best result when prediction. This decision is based on **accuracy, precision, recall, and f1** score on testing stage given machine learning models with **preprocessing** stage by doing remove punctuation, lowering, case, remove stopword, and stemming. Then using TF-IDF to **extract features** to be fed into the machine learning model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wacThzH1QK3g"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}